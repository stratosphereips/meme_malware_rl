import ember 
import numpy as np
from sklearn.utils import shuffle
from sklearn.metrics import accuracy_score, hamming_loss, confusion_matrix, recall_score, precision_score, roc_auc_score, roc_curve

import lightgbm as lgb
import os 

def get_ember_predictions(X_test):
    model = lgb.Booster(model_file='/data/mari/ember2018/ember_model_2018.txt')
    y_proba = model.predict(X_test)
    y_pred = [int(i > 0.8336) for i in y_proba]

    return y_pred



    
def get_ember_data(data_dir, seed=42):
    emberdf = ember.read_metadata(data_dir)
    X_train, y_train, X_test, y_test = ember.read_vectorized_features(data_dir)

    # Get the labels of the "unlabeled" data using the avclass column
    # This is only required for the dual input DNN but is done for all models
    # for reasons of uniformity.
    idx_unlab_mal = emberdf.query("label==-1")["avclass"].dropna().index
    idx_unlab_ben = emberdf[emberdf.avclass.isnull()].query("label == -1").index

    # Read the data and select the unlabeled instances
    X_train_mal = X_train[idx_unlab_mal]
    X_train_ben = X_train[idx_unlab_ben]

    y_train_ben = np.zeros(X_train_ben.shape[0])
    y_train_mal = np.ones(X_train_mal.shape[0])

    # Create the training dataset
    y_train = np.concatenate((y_train_ben, y_train_mal))
    X_train = np.vstack((X_train_ben, X_train_mal))

    X_train_unlab, y_train_unlab = shuffle(X_train, y_train, random_state=seed)

    return X_train_unlab, X_test, y_train_unlab, y_test


def train_surrogate(data_path, save_model_path, num_boosting_rounds):
    alpha = 0.1

    # Latest data
    X_rl = np.load(os.path.join(data_path, 'observations.npy'))
    y_rl = np.load(os.path.join(data_path, 'scores.npy'))

    # If we have prior observations append them here
    if os.path.exists(os.path.join(save_model_path, 'observations.npy')):
        X_old = np.load(os.path.join(save_model_path, 'observations.npy'))
        y_old = np.load(os.path.join(save_model_path, 'scores.npy'))

        X_rl = np.vstack((X_old, X_rl))
        y_rl = np.concatenate((y_old, y_rl))

    # Store data after merging
    np.save(os.path.join(save_model_path, 'observations.npy'), X_rl)
    np.save(os.path.join(save_model_path, 'scores.npy'), y_rl)

    X_train, X_test, y_train, y_test = get_ember_data('/data/mari/ember2018')

    t = X_rl.shape[0]
    m = X_train.shape[0]
    w_train = (1-alpha)*np.ones(m)*m/(m+t)
    w_rl = alpha*np.ones(t)*m/(m+t)

    X = np.vstack((X_train, X_rl))
    y = np.concatenate((y_train, y_rl))
    w = np.concatenate((w_train, w_rl))

    lgb_params = {
            "boosting_type" : "gbdt",
            "objective" : "binary",
            "learning_rate" : 0.05,
            "num_leaves": 2048,
            "max_depth" : 15,
            "min_child_samples": 30,
            "verbose": -1,
        }
    train_data = lgb.Dataset(X, label=y, weight=w)
    model = lgb.train(lgb_params, train_data,
            num_boost_round=num_boosting_rounds,
            # valid_sets=[self.val_data],
            verbose_eval=False,
            # early_stopping_rounds=30
        ) 

    y_proba = model.predict(X_test)
    y_pred_target = get_ember_predictions(X_test)
    evaluate_surrogate(y_proba, y_pred_target, y_test, 0.01)
    
    model.save_model(os.path.join(save_model_path, 'lgb_model.txt'))

def get_fpr(y_true, y_pred):
    """
        Given the true and predicted labels calculate the FPR.
        Uses the confusion_matrix() from scikit-learn.
    """
    tn, fp, _, _ = confusion_matrix(y_true, y_pred).ravel()
    fpr = fp / (tn + fp)
    return fpr

def find_threshold(y_true, y_pred, fpr_target):
    """
    Given the true labels and the probabilities of the model
    calculate the decision threshold for a given FPR level.
    """
    fpr, _, thresh = roc_curve(y_true, y_pred)
    return np.interp(fpr_target, fpr, thresh)


def evaluate_surrogate(y_proba, y_pred_target, y_test, fpr_target):
    thresh = find_threshold(y_test, y_proba, fpr_target)
    y_pred = [int(i > thresh) for i in y_proba]


    test_score = accuracy_score(y_test, y_pred)
    agg_score = 1.0 - hamming_loss(y_pred_target, y_pred)    
    fpr_score = get_fpr(y_test, y_pred)
    rec_score = recall_score(y_test, y_pred)
    pres_score = precision_score(y_test, y_pred)
    auc_score = roc_auc_score(y_test, y_pred)
    conf_mat = confusion_matrix(y_test, y_pred)

    print(f"Threshold for target FPR {fpr_target}: {thresh}")
    print("Accuracy score:", test_score)
    print("Agreement:", agg_score)
    print("FPR:", fpr_score)
    print("Recall:", rec_score)
    print("Precision:", pres_score)
    print("AUC:", auc_score)
    print("Confusion matrix:", conf_mat)
